\section{Related Work}
\label{sec:related}

Our work builds upon and connects several research areas in machine learning and information retrieval. We review the most relevant literature below.

\subsection{Dense Retrieval}
Dense retrieval has emerged as a powerful paradigm for information retrieval, with approaches like DPR~\cite{karpukhin2020dense}, ANCE~\cite{xiong2021approximate}, and ColBERT~\cite{khattab2020colbert} demonstrating the effectiveness of learned dense representations. While these methods achieve strong performance, they typically operate in flat Euclidean spaces, potentially limiting their ability to model complex semantic relationships.

\subsection{Geometric Deep Learning}
The idea of learning non-Euclidean representations has gained traction in geometric deep learning~\cite{bronstein2021geometric}. Recent work has explored hyperbolic~\cite{nickel2017poincare} and spherical~\cite{liu2019spherical} embeddings for various tasks. Our approach differs by learning the manifold structure directly from data rather than assuming a fixed geometry.

\subsection{Manifold Learning for NLP}
Several works have explored manifold learning in natural language processing. \citet{arora2018linear} proposed a random walk model on the word embedding manifold, while \citet{wang2020learning} learned document embeddings on a product manifold. Our work extends these ideas to the retrieval setting with a focus on end-to-end learning of the manifold structure.

\subsection{Curvature in Representation Learning}
The role of curvature in representation learning has been studied in various contexts. \citet{gu2018learning} explored learning curved embedding spaces for knowledge graphs, while \citet{skopek2020mixed} proposed mixed-curvature spaces for various tasks. Our work specifically addresses the challenge of learning curvature for retrieval tasks, with a novel focus on the relationship between curvature and semantic density.

\subsection{LLM-Aware Evaluation}
Recent work has highlighted the limitations of traditional IR metrics for evaluating retrieval systems in the context of LLMs~\cite{mao2023rethink}. Approaches like RAGAS~\cite{es2022ragas} and ARES~\cite{sai2023evaluating} have proposed LLM-based evaluation frameworks. Our RARE and SUD metrics build on these ideas while introducing novel geometric considerations.

\subsection{Differentiable Graph Learning}
Our approach leverages recent advances in differentiable graph algorithms~\cite{wang2019diffpool, vignac2022digress} to enable end-to-end learning of the manifold structure. This allows the model to adapt the geometry of the embedding space based on the retrieval objective.

\subsection{Positioning Our Work}
Our work distinguishes itself by:
\begin{itemize}
    \item Introducing a unified framework for learning both the embedding space and its geometry end-to-end
    \item Proposing curvature regularization specifically designed for retrieval tasks
    \item Developing LLM-aware evaluation metrics that account for the geometric properties of the embedding space
    \item Demonstrating the effectiveness of the approach on large-scale retrieval benchmarks
\end{itemize}

To the best of our knowledge, this is the first work that combines learnable manifold structures with LLM-aware evaluation for information retrieval, providing both theoretical insights and practical improvements over existing methods.
