\section{Introduction}
Modern retrieval systems have evolved from sparse TF-IDF indices to dense vector spaces where queries and documents are compared using inner products. While effective, this paradigm assumes the embedding space is flat and isotropic, which may not align with the complex, non-linear nature of linguistic meaning. This paper explores the potential of treating the embedding space as a \emph{learnable Riemannian manifold} to better capture the rich semantic structures in text.

\subsection{Motivation}
Our work is motivated by three key observations:

\begin{enumerate}
    \item \textbf{Geometric Mismatch}: Standard similarity metrics like cosine can misrepresent semantic relationships, especially in regions of varying semantic density. We propose using Ricci-Ollivier graph curvature to measure and correct this mismatch.
    
    \item \textbf{Evaluation Gap}: Traditional benchmarks provide limited relevance judgments, while modern RAG systems often generate correct answers using passages labeled as "irrelevant."
    
    \item \textbf{LLMs as Path-Finders}: Large Language Models can integrate information from multiple weakly relevant snippets. A properly curved latent space could better support this capability by reflecting meaningful semantic paths.
\end{enumerate}

\subsection{Contributions}
Our main contributions are:

\begin{itemize}
    \item \textbf{Response-aware Retrieval Effectiveness (RARE)}: A novel metric that evaluates retrieval quality based on the quality of LLM-generated responses.
    
    \item \textbf{Semantic Utility Delta (SUD)}: A measure that quantifies the marginal value of non-groundtruth documents in retrieval.
    
    \item \textbf{Curvature-guided Training}: A differentiable Ricci-Ollivier regularizer that shapes the embedding space to better reflect semantic relationships.
    
    \item \textbf{Comprehensive Evaluation}: Extensive experiments on standard benchmarks demonstrating the effectiveness of our approach.
\end{itemize}

The rest of this paper is organized as follows: Section~\ref{sec:related} reviews related work in geometric deep learning and information retrieval. Section~\ref{sec:method} details our methodology, followed by experiments in Section~\ref{sec:experiments} and results in Section~\ref{sec:results}. We conclude with a discussion of limitations and future work in Section~\ref{sec:conclusion}.
